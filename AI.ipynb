{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['airplane', 'bicycles', 'cars', 'motorbikes', 'ships']\n",
      "Training samples: 8908, Validation samples: 1908, Test samples: 1911\n",
      "Batch 0/279, Loss: 1.5686\n",
      "Batch 10/279, Loss: 0.8651\n",
      "Batch 20/279, Loss: 0.4970\n",
      "Batch 30/279, Loss: 0.3024\n",
      "Batch 40/279, Loss: 0.3242\n",
      "Batch 50/279, Loss: 0.2031\n",
      "Batch 60/279, Loss: 0.3176\n",
      "Batch 70/279, Loss: 0.0878\n",
      "Batch 80/279, Loss: 0.2787\n",
      "Batch 90/279, Loss: 0.1989\n",
      "Batch 100/279, Loss: 0.2269\n",
      "Batch 110/279, Loss: 0.3177\n",
      "Batch 120/279, Loss: 0.1463\n",
      "Batch 130/279, Loss: 0.0935\n",
      "Batch 140/279, Loss: 0.0978\n",
      "Batch 150/279, Loss: 0.2177\n",
      "Batch 160/279, Loss: 0.0571\n",
      "Batch 170/279, Loss: 0.0622\n",
      "Batch 180/279, Loss: 0.1350\n",
      "Batch 190/279, Loss: 0.0860\n",
      "Batch 200/279, Loss: 0.2817\n",
      "Batch 210/279, Loss: 0.1546\n",
      "Batch 220/279, Loss: 0.3634\n",
      "Batch 230/279, Loss: 0.1808\n",
      "Batch 240/279, Loss: 0.0953\n",
      "Batch 250/279, Loss: 0.2917\n",
      "Batch 260/279, Loss: 0.1382\n",
      "Batch 270/279, Loss: 0.1400\n",
      "Epoch 1/10, Loss: 0.2481, Accuracy: 93.20%\n",
      "Batch 0/279, Loss: 0.1319\n",
      "Batch 10/279, Loss: 0.1210\n",
      "Batch 20/279, Loss: 0.2161\n",
      "Batch 30/279, Loss: 0.0630\n",
      "Batch 40/279, Loss: 0.1596\n",
      "Batch 50/279, Loss: 0.1325\n",
      "Batch 60/279, Loss: 0.0744\n",
      "Batch 70/279, Loss: 0.2109\n",
      "Batch 80/279, Loss: 0.0270\n",
      "Batch 90/279, Loss: 0.0430\n",
      "Batch 100/279, Loss: 0.1332\n",
      "Batch 110/279, Loss: 0.1039\n",
      "Batch 120/279, Loss: 0.1226\n",
      "Batch 130/279, Loss: 0.3464\n",
      "Batch 140/279, Loss: 0.1446\n",
      "Batch 150/279, Loss: 0.0587\n",
      "Batch 160/279, Loss: 0.1762\n",
      "Batch 170/279, Loss: 0.1054\n",
      "Batch 180/279, Loss: 0.1617\n",
      "Batch 190/279, Loss: 0.0609\n",
      "Batch 200/279, Loss: 0.1962\n",
      "Batch 210/279, Loss: 0.1729\n",
      "Batch 220/279, Loss: 0.0511\n",
      "Batch 230/279, Loss: 0.2051\n",
      "Batch 240/279, Loss: 0.2725\n",
      "Batch 250/279, Loss: 0.1565\n",
      "Batch 260/279, Loss: 0.0725\n",
      "Batch 270/279, Loss: 0.0269\n",
      "Epoch 2/10, Loss: 0.1278, Accuracy: 95.82%\n",
      "Batch 0/279, Loss: 0.1236\n",
      "Batch 10/279, Loss: 0.0918\n",
      "Batch 20/279, Loss: 0.1100\n",
      "Batch 30/279, Loss: 0.0495\n",
      "Batch 40/279, Loss: 0.0179\n",
      "Batch 50/279, Loss: 0.0795\n",
      "Batch 60/279, Loss: 0.0188\n",
      "Batch 70/279, Loss: 0.0500\n",
      "Batch 80/279, Loss: 0.0080\n",
      "Batch 90/279, Loss: 0.0139\n",
      "Batch 100/279, Loss: 0.0297\n",
      "Batch 110/279, Loss: 0.1777\n",
      "Batch 120/279, Loss: 0.0586\n",
      "Batch 130/279, Loss: 0.0694\n",
      "Batch 140/279, Loss: 0.0421\n",
      "Batch 150/279, Loss: 0.0263\n",
      "Batch 160/279, Loss: 0.0540\n",
      "Batch 170/279, Loss: 0.1791\n",
      "Batch 180/279, Loss: 0.0473\n",
      "Batch 190/279, Loss: 0.1556\n",
      "Batch 200/279, Loss: 0.0355\n",
      "Batch 210/279, Loss: 0.0670\n",
      "Batch 220/279, Loss: 0.1517\n",
      "Batch 230/279, Loss: 0.0591\n",
      "Batch 240/279, Loss: 0.1061\n",
      "Batch 250/279, Loss: 0.1677\n",
      "Batch 260/279, Loss: 0.0793\n",
      "Batch 270/279, Loss: 0.0274\n",
      "Epoch 3/10, Loss: 0.1181, Accuracy: 96.21%\n",
      "Batch 0/279, Loss: 0.1347\n",
      "Batch 10/279, Loss: 0.4627\n",
      "Batch 20/279, Loss: 0.1986\n",
      "Batch 30/279, Loss: 0.1680\n",
      "Batch 40/279, Loss: 0.1317\n",
      "Batch 50/279, Loss: 0.1004\n",
      "Batch 60/279, Loss: 0.1870\n",
      "Batch 70/279, Loss: 0.2119\n",
      "Batch 80/279, Loss: 0.0726\n",
      "Batch 90/279, Loss: 0.0043\n",
      "Batch 100/279, Loss: 0.1387\n",
      "Batch 110/279, Loss: 0.0387\n",
      "Batch 120/279, Loss: 0.0593\n",
      "Batch 130/279, Loss: 0.0650\n",
      "Batch 140/279, Loss: 0.0849\n",
      "Batch 150/279, Loss: 0.0272\n",
      "Batch 160/279, Loss: 0.0760\n",
      "Batch 170/279, Loss: 0.2053\n",
      "Batch 180/279, Loss: 0.1227\n",
      "Batch 190/279, Loss: 0.1316\n",
      "Batch 200/279, Loss: 0.0548\n",
      "Batch 210/279, Loss: 0.1025\n",
      "Batch 220/279, Loss: 0.0084\n",
      "Batch 230/279, Loss: 0.3938\n",
      "Batch 240/279, Loss: 0.0067\n",
      "Batch 250/279, Loss: 0.1478\n",
      "Batch 260/279, Loss: 0.0516\n",
      "Batch 270/279, Loss: 0.4440\n",
      "Epoch 4/10, Loss: 0.1160, Accuracy: 96.05%\n",
      "Batch 0/279, Loss: 0.1260\n",
      "Batch 10/279, Loss: 0.0453\n",
      "Batch 20/279, Loss: 0.1795\n",
      "Batch 30/279, Loss: 0.0607\n",
      "Batch 40/279, Loss: 0.0163\n",
      "Batch 50/279, Loss: 0.0880\n",
      "Batch 60/279, Loss: 0.2306\n",
      "Batch 70/279, Loss: 0.2610\n",
      "Batch 80/279, Loss: 0.0602\n",
      "Batch 90/279, Loss: 0.0707\n",
      "Batch 100/279, Loss: 0.0684\n",
      "Batch 110/279, Loss: 0.0158\n",
      "Batch 120/279, Loss: 0.0639\n",
      "Batch 130/279, Loss: 0.2265\n",
      "Batch 140/279, Loss: 0.0509\n",
      "Batch 150/279, Loss: 0.0153\n",
      "Batch 160/279, Loss: 0.0587\n",
      "Batch 170/279, Loss: 0.0864\n",
      "Batch 180/279, Loss: 0.0325\n",
      "Batch 190/279, Loss: 0.0168\n",
      "Batch 200/279, Loss: 0.0314\n",
      "Batch 210/279, Loss: 0.0608\n",
      "Batch 220/279, Loss: 0.1028\n",
      "Batch 230/279, Loss: 0.0691\n",
      "Batch 240/279, Loss: 0.1410\n",
      "Batch 250/279, Loss: 0.2935\n",
      "Batch 260/279, Loss: 0.4336\n",
      "Batch 270/279, Loss: 0.0682\n",
      "Epoch 5/10, Loss: 0.1005, Accuracy: 96.49%\n",
      "Batch 0/279, Loss: 0.1044\n",
      "Batch 10/279, Loss: 0.0522\n",
      "Batch 20/279, Loss: 0.1796\n",
      "Batch 30/279, Loss: 0.0510\n",
      "Batch 40/279, Loss: 0.2490\n",
      "Batch 50/279, Loss: 0.0303\n",
      "Batch 60/279, Loss: 0.1413\n",
      "Batch 70/279, Loss: 0.0471\n",
      "Batch 80/279, Loss: 0.1578\n",
      "Batch 90/279, Loss: 0.0313\n",
      "Batch 100/279, Loss: 0.0279\n",
      "Batch 110/279, Loss: 0.1566\n",
      "Batch 120/279, Loss: 0.1199\n",
      "Batch 130/279, Loss: 0.0306\n",
      "Batch 140/279, Loss: 0.1331\n",
      "Batch 150/279, Loss: 0.0646\n",
      "Batch 160/279, Loss: 0.2812\n",
      "Batch 170/279, Loss: 0.0491\n",
      "Batch 180/279, Loss: 0.0628\n",
      "Batch 190/279, Loss: 0.1718\n",
      "Batch 200/279, Loss: 0.0041\n",
      "Batch 210/279, Loss: 0.0635\n",
      "Batch 220/279, Loss: 0.0632\n",
      "Batch 230/279, Loss: 0.1571\n",
      "Batch 240/279, Loss: 0.0420\n",
      "Batch 250/279, Loss: 0.1870\n",
      "Batch 260/279, Loss: 0.0740\n",
      "Batch 270/279, Loss: 0.0606\n",
      "Epoch 6/10, Loss: 0.1002, Accuracy: 96.63%\n",
      "Batch 0/279, Loss: 0.2339\n",
      "Batch 10/279, Loss: 0.0442\n",
      "Batch 20/279, Loss: 0.0360\n",
      "Batch 30/279, Loss: 0.0357\n",
      "Batch 40/279, Loss: 0.0563\n",
      "Batch 50/279, Loss: 0.0137\n",
      "Batch 60/279, Loss: 0.0219\n",
      "Batch 70/279, Loss: 0.0312\n",
      "Batch 80/279, Loss: 0.3417\n",
      "Batch 90/279, Loss: 0.0149\n",
      "Batch 100/279, Loss: 0.0234\n",
      "Batch 110/279, Loss: 0.1412\n",
      "Batch 120/279, Loss: 0.0582\n",
      "Batch 130/279, Loss: 0.0555\n",
      "Batch 140/279, Loss: 0.0814\n",
      "Batch 150/279, Loss: 0.0521\n",
      "Batch 160/279, Loss: 0.0170\n",
      "Batch 170/279, Loss: 0.2217\n",
      "Batch 180/279, Loss: 0.0694\n",
      "Batch 190/279, Loss: 0.2023\n",
      "Batch 200/279, Loss: 0.1544\n",
      "Batch 210/279, Loss: 0.1086\n",
      "Batch 220/279, Loss: 0.0459\n",
      "Batch 230/279, Loss: 0.0235\n",
      "Batch 240/279, Loss: 0.0125\n",
      "Batch 250/279, Loss: 0.0178\n",
      "Batch 260/279, Loss: 0.4533\n",
      "Batch 270/279, Loss: 0.0494\n",
      "Epoch 7/10, Loss: 0.0995, Accuracy: 96.97%\n",
      "Batch 0/279, Loss: 0.1484\n",
      "Batch 10/279, Loss: 0.0165\n",
      "Batch 20/279, Loss: 0.0345\n",
      "Batch 30/279, Loss: 0.1685\n",
      "Batch 40/279, Loss: 0.0784\n",
      "Batch 50/279, Loss: 0.1169\n",
      "Batch 60/279, Loss: 0.1836\n",
      "Batch 70/279, Loss: 0.0438\n",
      "Batch 80/279, Loss: 0.0597\n",
      "Batch 90/279, Loss: 0.1074\n",
      "Batch 100/279, Loss: 0.0888\n",
      "Batch 110/279, Loss: 0.0312\n",
      "Batch 120/279, Loss: 0.1489\n",
      "Batch 130/279, Loss: 0.0900\n",
      "Batch 140/279, Loss: 0.0775\n",
      "Batch 150/279, Loss: 0.2494\n",
      "Batch 160/279, Loss: 0.0697\n",
      "Batch 170/279, Loss: 0.5897\n",
      "Batch 180/279, Loss: 0.0236\n",
      "Batch 190/279, Loss: 0.1551\n",
      "Batch 200/279, Loss: 0.0873\n",
      "Batch 210/279, Loss: 0.0243\n",
      "Batch 220/279, Loss: 0.0120\n",
      "Batch 230/279, Loss: 0.0463\n",
      "Batch 240/279, Loss: 0.1815\n",
      "Batch 250/279, Loss: 0.0931\n",
      "Batch 260/279, Loss: 0.2172\n",
      "Batch 270/279, Loss: 0.0269\n",
      "Epoch 8/10, Loss: 0.0989, Accuracy: 96.58%\n",
      "Batch 0/279, Loss: 0.2629\n",
      "Batch 10/279, Loss: 0.0101\n",
      "Batch 20/279, Loss: 0.0054\n",
      "Batch 30/279, Loss: 0.0287\n",
      "Batch 40/279, Loss: 0.1103\n",
      "Batch 50/279, Loss: 0.0662\n",
      "Batch 60/279, Loss: 0.0634\n",
      "Batch 70/279, Loss: 0.0688\n",
      "Batch 80/279, Loss: 0.0585\n",
      "Batch 90/279, Loss: 0.0198\n",
      "Batch 100/279, Loss: 0.1117\n",
      "Batch 110/279, Loss: 0.0157\n",
      "Batch 120/279, Loss: 0.1895\n",
      "Batch 130/279, Loss: 0.0902\n",
      "Batch 140/279, Loss: 0.0137\n",
      "Batch 150/279, Loss: 0.0010\n",
      "Batch 160/279, Loss: 0.0734\n",
      "Batch 170/279, Loss: 0.0601\n",
      "Batch 180/279, Loss: 0.0798\n",
      "Batch 190/279, Loss: 0.0378\n",
      "Batch 200/279, Loss: 0.1653\n",
      "Batch 210/279, Loss: 0.1623\n",
      "Batch 220/279, Loss: 0.0061\n",
      "Batch 230/279, Loss: 0.1097\n",
      "Batch 240/279, Loss: 0.0144\n",
      "Batch 250/279, Loss: 0.0695\n",
      "Batch 260/279, Loss: 0.0035\n",
      "Batch 270/279, Loss: 0.0870\n",
      "Epoch 9/10, Loss: 0.0932, Accuracy: 96.70%\n",
      "Batch 0/279, Loss: 0.2002\n",
      "Batch 10/279, Loss: 0.0277\n",
      "Batch 20/279, Loss: 0.0577\n",
      "Batch 30/279, Loss: 0.2152\n",
      "Batch 40/279, Loss: 0.0573\n",
      "Batch 50/279, Loss: 0.1215\n",
      "Batch 60/279, Loss: 0.0278\n",
      "Batch 70/279, Loss: 0.2606\n",
      "Batch 80/279, Loss: 0.1445\n",
      "Batch 90/279, Loss: 0.0113\n",
      "Batch 100/279, Loss: 0.0525\n",
      "Batch 110/279, Loss: 0.0084\n",
      "Batch 120/279, Loss: 0.0457\n",
      "Batch 130/279, Loss: 0.1284\n",
      "Batch 140/279, Loss: 0.0329\n",
      "Batch 150/279, Loss: 0.1168\n",
      "Batch 160/279, Loss: 0.1391\n",
      "Batch 170/279, Loss: 0.0043\n",
      "Batch 180/279, Loss: 0.0185\n",
      "Batch 190/279, Loss: 0.1156\n",
      "Batch 200/279, Loss: 0.0414\n",
      "Batch 210/279, Loss: 0.0697\n",
      "Batch 220/279, Loss: 0.0869\n",
      "Batch 230/279, Loss: 0.1201\n",
      "Batch 240/279, Loss: 0.1026\n",
      "Batch 250/279, Loss: 0.2390\n",
      "Batch 260/279, Loss: 0.1303\n",
      "Batch 270/279, Loss: 0.0117\n",
      "Epoch 10/10, Loss: 0.0995, Accuracy: 96.65%\n",
      "Model saved.\n",
      "Test image path does not exist: /Users/user/Documents/I5/AI/Final_AI_Project/sample_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Paths to dataset\n",
    "dataset_path = \"/Users/user/Documents/I5/AI/Final_AI_Project/split_dataset\"\n",
    "train_path = f\"{dataset_path}/train\"\n",
    "val_path = f\"{dataset_path}/val\"\n",
    "test_path = f\"{dataset_path}/test\"\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_path, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_path, transform=data_transforms['test'])\n",
    "\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Load pre-trained ResNet model\n",
    "pretrained_model = models.resnet50(pretrained=True)\n",
    "num_classes = len(train_dataset.classes)\n",
    "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, num_classes)\n",
    "\n",
    "# Freeze all layers except the final fully connected\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in pretrained_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pretrained_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pretrained_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Batch {i}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "torch.save(pretrained_model.state_dict(), \"resnet50_vehicle_classifier.pth\")\n",
    "print(\"Model saved.\")\n",
    "\n",
    "# Prediction\n",
    "def predict_image(model, image_path, class_names):\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = outputs.max(1)\n",
    "        return class_names[predicted.item()]\n",
    "\n",
    "test_image_path = \"/Users/user/Documents/I5/AI/Final_AI_Project/sample_image.jpg\"\n",
    "if os.path.exists(test_image_path):\n",
    "    predicted_class = predict_image(pretrained_model, test_image_path, train_dataset.classes)\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "else:\n",
    "    print(f\"Test image path does not exist: {test_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rh/pb3vmf1d43d_z4xt5jr0bmwr0000gn/T/ipykernel_46444/1703366878.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_model.load_state_dict(torch.load(\"resnet50_vehicle_classifier.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models, datasets\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Reload class names dynamically\n",
    "train_dataset_path = \"/Users/user/Documents/I5/AI/Final_AI_Project/split_dataset/train\"\n",
    "train_dataset = datasets.ImageFolder(train_dataset_path)\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Reload the model\n",
    "pretrained_model = models.resnet50(pretrained=False)  # Set pretrained to False\n",
    "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, num_classes)\n",
    "\n",
    "# Load trained weights\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model.load_state_dict(torch.load(\"resnet50_vehicle_classifier.pth\", map_location=device))\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have stored the loss and accuracy values during training\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "train_losses = []  # Fill this with the training loss values\n",
    "train_accuracies = []  # Fill this with the training accuracy values\n",
    "\n",
    "# Plotting the loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
